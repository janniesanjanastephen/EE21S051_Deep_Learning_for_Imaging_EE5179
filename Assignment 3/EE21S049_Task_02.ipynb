{"cells":[{"cell_type":"markdown","metadata":{"id":"XAjZsNemiGY2"},"source":["# 2 - Improving Performance\n","\n","In the previous notebook, we got the fundamentals down for sentiment analysis. In this notebook, we'll actually get decent results.\n","\n","We will use:\n","- bidirectional RNN\n","- multi-layer RNN\n","\n","This will allow us to achieve ~84% test accuracy."]},{"cell_type":"markdown","metadata":{"id":"3c53mzb7iGY7"},"source":["## Preparing Data"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3YrJix0ipF8","outputId":"f00045cf-12eb-449c-bc7e-50ff8eb661ab","executionInfo":{"status":"ok","timestamp":1664615339696,"user_tz":-330,"elapsed":103714,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 8.0 MB/s \n","\u001b[?25hCollecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}],"source":["!pip install torchtext==0.10.0"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"nnAhxOmniGY8","executionInfo":{"status":"ok","timestamp":1664615352975,"user_tz":-330,"elapsed":13286,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["import torch\n","from torchtext.legacy import data\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize = 'spacy',\n","                  tokenizer_language = 'en_core_web_sm')\n","\n","LABEL = data.LabelField(dtype = torch.float)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCnFCkp8iGY_","outputId":"23697cf6-c785-43ca-82cb-0d540a2d29c8","executionInfo":{"status":"ok","timestamp":1664615420238,"user_tz":-330,"elapsed":67272,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["downloading aclImdb_v1.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 62.1MB/s]\n"]}],"source":["from torchtext.legacy import datasets\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"n7Mgh59EiGZA","executionInfo":{"status":"ok","timestamp":1664615420239,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["import random\n","\n","train_data, valid_data = train_data.split(random_state = random.seed(SEED))"]},{"cell_type":"markdown","metadata":{"id":"qI5sKl_JiGZB"},"source":["Next is the use of pre-trained word embeddings. Now, instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors.\n","We get these vectors simply by specifying which vectors we want and passing it as an argument to `build_vocab`. `TorchText` handles downloading the vectors and associating them with the correct words in our vocabulary.\n","\n","Here, we'll be using the `\"glove.6B.100d\" vectors\"`. `glove` is the algorithm used to calculate the vectors, go [here](https://nlp.stanford.edu/projects/glove/) for more. `6B` indicates these vectors were trained on 6 billion tokens and `100d` indicates these vectors are 100-dimensional.\n","\n","You can see the other available vectors [here](https://github.com/pytorch/text/blob/master/torchtext/vocab.py#L113).\n","\n","The theory is that these pre-trained vectors already have words with similar semantic meaning close together in vector space, e.g. \"terrible\", \"awful\", \"dreadful\" are nearby. This gives our embedding layer a good initialization as it does not have to learn these relations from scratch."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUiMbHqDiGZC","outputId":"02d690ca-9ede-4bad-c227-2365fb591fc0","executionInfo":{"status":"ok","timestamp":1664615690586,"user_tz":-330,"elapsed":194145,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stderr","text":[".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n","100%|█████████▉| 399999/400000 [00:13<00:00, 29476.54it/s]\n"]}],"source":["MAX_VOCAB_SIZE = 25_000\n","\n","TEXT.build_vocab(train_data, \n","                 max_size = MAX_VOCAB_SIZE, \n","                 vectors = \"glove.6B.100d\", \n","                 unk_init = torch.Tensor.normal_)\n","\n","LABEL.build_vocab(train_data)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0j9QLueUiGZE","executionInfo":{"status":"ok","timestamp":1664615690587,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    device = device)"]},{"cell_type":"markdown","metadata":{"id":"Ypnhdw1JiGZE"},"source":["## Build the Model\n","\n","### Different RNN Architecture\n","\n","We'll be using a different RNN architecture called a Long Short-Term Memory (LSTM). Why is an LSTM better than a standard RNN? Standard RNNs suffer from the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). LSTMs overcome this by having an extra recurrent state called a _cell_, $c$ - which can be thought of as the \"memory\" of the LSTM - and the use use multiple _gates_ which control the flow of information into and out of the memory. For more information, go [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). We can simply think of the LSTM as a function of $x_t$, $h_t$ and $c_t$, instead of just $x_t$ and $h_t$.\n","\n","$$(h_t, c_t) = \\text{LSTM}(x_t, h_t, c_t)$$\n","\n","Thus, the model using an LSTM looks something like (with the embedding layers omitted):\n","\n","![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment2.png?raw=1)\n","\n","The initial cell state, $c_0$, like the initial hidden state is initialized to a tensor of all zeros. The sentiment prediction is still, however, only made using the final hidden state, not the final cell state, i.e. $\\hat{y}=f(h_T)$.\n","\n","### Bidirectional RNN\n","\n","The concept behind a bidirectional RNN is simple. As well as having an RNN processing the words in the sentence from the first to the last (a forward RNN), we have a second RNN processing the words in the sentence from the **last to the first** (a backward RNN). At time step $t$, the forward RNN is processing word $x_t$, and the backward RNN is processing word $x_{T-t+1}$. \n","\n","In PyTorch, the hidden state (and cell state) tensors returned by the forward and backward RNNs are stacked on top of each other in a single tensor. \n","\n","We make our sentiment prediction using a concatenation of the last hidden state from the forward RNN (obtained from final word of the sentence), $h_T^\\rightarrow$, and the last hidden state from the backward RNN (obtained from the first word of the sentence), $h_T^\\leftarrow$, i.e. $\\hat{y}=f(h_T^\\rightarrow, h_T^\\leftarrow)$   \n","\n","The image below shows a bi-directional RNN, with the forward RNN in orange, the backward RNN in green and the linear layer in silver.  \n","\n","![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment3.png?raw=1)\n","\n","### Multi-layer RNN\n","\n","Multi-layer RNNs (also called *deep RNNs*) are another simple concept. The idea is that we add additional RNNs on top of the initial standard RNN, where each RNN added is another *layer*. The hidden state output by the first (bottom) RNN at time-step $t$ will be the input to the RNN above it at time step $t$. The prediction is then made from the final hidden state of the final (highest) layer.\n","\n","The image below shows a multi-layer unidirectional RNN, where the layer number is given as a superscript. Also note that each layer needs their own initial hidden state, $h_0^L$.\n","\n","![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment4.png?raw=1)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gxvtce0x0ggj","executionInfo":{"status":"ok","timestamp":1664617646018,"user_tz":-330,"elapsed":351,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["import torch.nn as nn\n","\n","class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        self.rnn = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","        \n","        #text = [sent len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(text))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        output, (hidden, cell) = self.rnn(embedded)\n","\n","        #output = [sent len, batch size, hid dim * num directions]\n","        #output over padding tokens are zero tensors\n","        \n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        #cell = [num layers * num directions, batch size, hid dim]\n","        \n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","        \n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","                \n","        #hidden = [batch size, hid dim * num directions]\n","            \n","        return self.fc(hidden)"]},{"cell_type":"code","source":[],"metadata":{"id":"bC_04eRB0ZQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Ad1sTsNviGZG","executionInfo":{"status":"ok","timestamp":1664617650685,"user_tz":-330,"elapsed":409,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = RNN(INPUT_DIM, \n","            EMBEDDING_DIM, \n","            HIDDEN_DIM, \n","            OUTPUT_DIM, \n","            N_LAYERS, \n","            BIDIRECTIONAL, \n","            DROPOUT, \n","            PAD_IDX)"]},{"cell_type":"markdown","metadata":{"id":"hNH78tYAiGZH"},"source":["We'll print out the number of parameters in our model. \n","\n","Notice how we have almost twice as many parameters as before!"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmbICY8FiGZH","outputId":"54484fb1-9b2b-4fa5-aeac-71880290030f","executionInfo":{"status":"ok","timestamp":1664617653862,"user_tz":-330,"elapsed":413,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 4,810,857 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"markdown","metadata":{"id":"-YeLINmbiGZI"},"source":["The final addition is copying the pre-trained word embeddings we loaded earlier into the `embedding` layer of our model.\n","\n","We retrieve the embeddings from the field's vocab, and check they're the correct size, _**[vocab size, embedding dim]**_ "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0IGwTZhiGZI","outputId":"fd47a185-97e0-4e44-b942-5f2b5a28430b","executionInfo":{"status":"ok","timestamp":1664617657353,"user_tz":-330,"elapsed":356,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([25002, 100])\n"]}],"source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","print(pretrained_embeddings.shape)"]},{"cell_type":"markdown","metadata":{"id":"jMCPa3MZiGZI"},"source":["We then replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n","\n","**Note**: this should always be done on the `weight.data` and not the `weight`!"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5yVKOjPiGZI","outputId":"d5cdf2d1-0e4c-4771-b459-c6f14cef7605","executionInfo":{"status":"ok","timestamp":1664617772288,"user_tz":-330,"elapsed":358,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n","        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n","        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n","        ...,\n","        [ 0.1068, -0.0572, -0.5956,  ...,  2.1442,  1.2027,  0.3947],\n","        [ 0.3749, -0.0187, -0.3940,  ..., -0.5277,  0.0937, -1.1152],\n","        [ 0.1787,  0.1934, -0.0216,  ..., -0.1655,  0.3625, -0.2256]])"]},"metadata":{},"execution_count":11}],"source":["model.embedding.weight.data.copy_(pretrained_embeddings)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KgrxEvGOiGZJ","outputId":"bce3a733-2799-48d3-d227-fb2fbf15c7aa","executionInfo":{"status":"ok","timestamp":1664617777267,"user_tz":-330,"elapsed":1546,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n","        ...,\n","        [ 0.1068, -0.0572, -0.5956,  ...,  2.1442,  1.2027,  0.3947],\n","        [ 0.3749, -0.0187, -0.3940,  ..., -0.5277,  0.0937, -1.1152],\n","        [ 0.1787,  0.1934, -0.0216,  ..., -0.1655,  0.3625, -0.2256]])\n"]}],"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.embedding.weight.data)"]},{"cell_type":"markdown","metadata":{"id":"5t_wnKSNiGZJ"},"source":["## Train the Model"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"qhCC_d2ziGZK","executionInfo":{"status":"ok","timestamp":1664618877660,"user_tz":-330,"elapsed":621,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["import torch.optim as optim\n","\n","# optimizer = optim.SGD(model.parameters(), lr=1e-3)\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"OTG0F2U7iGZK","executionInfo":{"status":"ok","timestamp":1664618879490,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"YzTun-JNiGZK","executionInfo":{"status":"ok","timestamp":1664618881682,"user_tz":-330,"elapsed":345,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["def binary_accuracy(preds, y):\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"KHQ2PRhnk3wb","executionInfo":{"status":"ok","timestamp":1664618883794,"user_tz":-330,"elapsed":410,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"L68FdNGziGZL","executionInfo":{"status":"ok","timestamp":1664618884661,"user_tz":-330,"elapsed":350,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in tqdm(iterator):\n","        \n","        optimizer.zero_grad()\n","        \n","        predictions = model(batch.text).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"j9SQuS0KiGZL","executionInfo":{"status":"ok","timestamp":1664618886217,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in tqdm(iterator):\n","            \n","            predictions = model(batch.text).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"XUuz7hkwiGZL","executionInfo":{"status":"ok","timestamp":1664618887894,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[],"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctGpVoShiGZM","outputId":"c644ac52-c5b4-4a2d-921a-5551344fac0c","executionInfo":{"status":"ok","timestamp":1664619089022,"user_tz":-330,"elapsed":196625,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 274/274 [00:33<00:00,  8.12it/s]\n","100%|██████████| 118/118 [00:04<00:00, 26.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 0m 38s\n","\tTrain Loss: 0.683 | Train Acc: 55.92%\n","\t Val. Loss: 0.667 |  Val. Acc: 59.77%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 274/274 [00:34<00:00,  7.97it/s]\n","100%|██████████| 118/118 [00:04<00:00, 26.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 02 | Epoch Time: 0m 38s\n","\tTrain Loss: 0.673 | Train Acc: 58.51%\n","\t Val. Loss: 0.648 |  Val. Acc: 64.49%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 274/274 [00:35<00:00,  7.82it/s]\n","100%|██████████| 118/118 [00:04<00:00, 25.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 03 | Epoch Time: 0m 39s\n","\tTrain Loss: 0.658 | Train Acc: 61.34%\n","\t Val. Loss: 0.599 |  Val. Acc: 64.42%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 274/274 [00:35<00:00,  7.79it/s]\n","100%|██████████| 118/118 [00:04<00:00, 25.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 04 | Epoch Time: 0m 39s\n","\tTrain Loss: 0.609 | Train Acc: 66.96%\n","\t Val. Loss: 0.555 |  Val. Acc: 72.48%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 274/274 [00:35<00:00,  7.79it/s]\n","100%|██████████| 118/118 [00:04<00:00, 25.47it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 05 | Epoch Time: 0m 39s\n","\tTrain Loss: 0.541 | Train Acc: 74.02%\n","\t Val. Loss: 0.436 |  Val. Acc: 80.54%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["N_EPOCHS = 5\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut7-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iEIJg2qsiGZM","outputId":"d01a0337-9124-462f-a30c-22697a4e9921","executionInfo":{"status":"ok","timestamp":1664619113101,"user_tz":-330,"elapsed":14992,"user":{"displayName":"Sneha Sree C ee21s049","userId":"00612408101697203065"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:14<00:00, 26.46it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.454 | Test Acc: 79.47%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model.load_state_dict(torch.load('tut7-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}